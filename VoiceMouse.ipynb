{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1920\n",
      "1080\n"
     ]
    }
   ],
   "source": [
    "import pyautogui\n",
    "import speech_recognition as sr\n",
    "\n",
    "screenWidth, screenHeight = pyautogui.size() # Get the size of the primary monitor.\n",
    "#currentMouseX, currentMouseY = pyautogui.position() # Get the XY position of the mouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mouse movement functions\n",
    "\n",
    "def mouse_down(percent):\n",
    "    pixels = percent/100.0 * screenHeight\n",
    "    pyautogui.move(0, pixels) \n",
    "\n",
    "def mouse_up(percent):\n",
    "    pixels = percent/-100.0 * screenHeight\n",
    "    pyautogui.move(0, pixels)   \n",
    "    \n",
    "def mouse_right(percent):\n",
    "    pixels = percent/100.0 * screenWidth\n",
    "    pyautogui.move(pixels, 0)\n",
    "    \n",
    "def mouse_left(percent):\n",
    "    pixels = percent/-100.0 * screenWidth\n",
    "    pyautogui.move(pixels, 0)\n",
    "    \n",
    "def bit_down():\n",
    "    pyautogui.move(0, 10) \n",
    "    \n",
    "def bit_up():\n",
    "    pyautogui.move(0, -10) \n",
    "    \n",
    "def bit_right():\n",
    "    pyautogui.move(10, 0) \n",
    "    \n",
    "def bit_left():\n",
    "    pyautogui.move(-10, 0) \n",
    "    \n",
    "def click():\n",
    "    pyautogui.click()\n",
    "    \n",
    "def doubleclick():\n",
    "    pyautogui.doubleClick()\n",
    "    \n",
    "#scrolling only works if in correct cursor location (maybe move to center)\n",
    "def scroll_up():\n",
    "     pyautogui.scroll(100) \n",
    "    \n",
    "def scroll_down():\n",
    "     pyautogui.scroll(-100) \n",
    "        \n",
    "def scroll_right():\n",
    "    pyautogui.hscroll(10)\n",
    "\n",
    "def scroll_left():\n",
    "     pyautogui.hscroll(-10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_speech_from_mic(recognizer, microphone):\n",
    "    \"\"\"Transcribe speech from recorded from `microphone`.\n",
    "    Returns a dictionary with three keys:\n",
    "    \"success\": a boolean indicating whether or not the API request was\n",
    "               successful\n",
    "    \"error\":   `None` if no error occured, otherwise a string containing\n",
    "               an error message if the API could not be reached or\n",
    "               speech was unrecognizable\n",
    "    \"transcription\": `None` if speech could not be transcribed,\n",
    "               otherwise a string containing the transcribed text\n",
    "    \"\"\"\n",
    "    # check that recognizer and microphone arguments are appropriate type\n",
    "    if not isinstance(recognizer, sr.Recognizer):\n",
    "        raise TypeError(\"`recognizer` must be `Recognizer` instance\")\n",
    "\n",
    "    if not isinstance(microphone, sr.Microphone):\n",
    "        raise TypeError(\"`microphone` must be `Microphone` instance\")\n",
    "\n",
    "    # adjust the recognizer sensitivity to ambient noise and record audio\n",
    "    # from the microphone\n",
    "    with microphone as source:\n",
    "        recognizer.adjust_for_ambient_noise(source) #analyze the audio source for 1 second\n",
    "        audio = recognizer.listen(source)\n",
    "\n",
    "    # set up the response object\n",
    "    response = {\n",
    "        \"success\": True,\n",
    "        \"error\": None,\n",
    "        \"transcription\": None\n",
    "    }\n",
    "\n",
    "    # try recognizing the speech in the recording\n",
    "    # if a RequestError or UnknownValueError exception is caught,\n",
    "    #   update the response object accordingly\n",
    "    try:\n",
    "        response[\"transcription\"] = recognizer.recognize_google(audio)\n",
    "    except sr.RequestError:\n",
    "        # API was unreachable or unresponsive\n",
    "        response[\"success\"] = False\n",
    "        response[\"error\"] = \"API unavailable/unresponsive\"\n",
    "    except sr.UnknownValueError:\n",
    "        # speech was unintelligible\n",
    "        response[\"error\"] = \"Unable to recognize speech\"\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Success : True\n",
      "Error   : Unable to recognize speech\n",
      "\n",
      "Text from Speech\n",
      "-----------------\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "recognizer = sr.Recognizer()\n",
    "mic = sr.Microphone(device_index=1)\n",
    "response = recognize_speech_from_mic(recognizer, mic)\n",
    "\n",
    "speech =  response['transcription']\n",
    "\n",
    "if (response['success'] == True):\n",
    "    print(speech)\n",
    "    \n",
    "else:\n",
    "    print('failed')\n",
    "\n",
    "print('\\nSuccess : {}\\nError   : {}\\n\\nText from Speech\\n{}\\n\\n{}' \\\n",
    "      .format(response['success'],\n",
    "              response['error'],\n",
    "              '-'*17,\n",
    "              response['transcription']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech = 'mouse left 10'\n",
    "bit_amount = 10\n",
    "\n",
    "#basic way to approach commands, probably changing this to be more versitatile later\n",
    "def action(speech):\n",
    "\n",
    "    speech_tokens = speech.split()\n",
    "\n",
    "    #move mouse\n",
    "    if ('mouse' in speech_tokens):\n",
    "        try:\n",
    "            percent = int(speech_tokens[-1])\n",
    "        except ValueError:\n",
    "            percent = 20\n",
    "        if ('down' in speech_tokens):\n",
    "            mouse_down(percent)\n",
    "        elif ('up' in speech_tokens):\n",
    "            mouse_up(percent)\n",
    "        elif ('right' in speech_tokens):\n",
    "            mouse_right(percent)\n",
    "        elif ('left' in speech_tokens):\n",
    "            mouse_left(percent)\n",
    "\n",
    "    #move mouse slightly\n",
    "    elif ('bit' in speech_tokens):\n",
    "        if ('down' in speech_tokens):\n",
    "            bit_down(bit_amount)\n",
    "        elif ('up' in speech_tokens):\n",
    "            bit_up(bit_amount)\n",
    "        elif ('right' in speech_tokens):\n",
    "            bit_right(bit_amount)\n",
    "        elif ('left' in speech_tokens):\n",
    "            bit_left(bit_amount)\n",
    "\n",
    "    #scroll\n",
    "    elif ('scroll' in speech_tokens):\n",
    "        if ('down' in speech_tokens):\n",
    "            scroll_down(scroll_amount)\n",
    "        elif ('up' in speech_tokens):\n",
    "            scroll_up(scroll_amount)\n",
    "        elif ('right' in speech_tokens):\n",
    "            scroll_right(scroll_amount)\n",
    "        elif ('left' in speech_tokens):\n",
    "            scroll_left(scroll_amount)\n",
    "\n",
    "    #click\n",
    "    elif ('click' in speech_tokens):\n",
    "        click()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
